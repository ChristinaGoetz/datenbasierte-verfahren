{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"provenance":[{"file_id":"1ZrffY5dhnOj2nENKdJq-fNl8S3rsfMrJ","timestamp":1699533665200},{"file_id":"https://github.com/DeepLearningForPhysicsResearchBook/deep-learning-physics/blob/main/Exercise_03_3_solution.ipynb","timestamp":1632316399384}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1byLAw-So3T5"},"source":["# Workshop Artificial Intelligence\n","\n","## Checkerboard\n","\n","Open the Tensorflow Playground ([playground.tensorflow.org](https://playground.tensorflow.org )) and select on the left the checkerboard pattern (\"exclusive or\") as the data basis.\n","\n","The data is taken from a two-dimensional probability distribution and is represented by the value pairs $x_1$ and $x_2$. The regions $x1$, $x_2 > 0$ and $x_1$, $x_2 < 0$ are shown by one color. For value pairs with $x_1 > 0$, $x_2 < 0$ and $x_1 < 0$, $x_2 > 0$, the regions are indicated by a different color.  \n","\n","In features, select the two independent variables $x_1$ and $x_2$ and start the network training. The network learns that $x_1$ and $x_2$ are for these data not independent variables, but are taken from the probability distribution of the checkerboard pattern.\n","\n","[![Checkerboard](https://github.com/DeepLearningForPhysicsResearchBook/deep-learning-physics/blob/main/images/checkerboard_tf_playground.png?raw=1)](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.20784&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n","\n","## Tasks\n","1.  Try various settings for the number of layers and neurons using `ReLU` as activation function. What is the smallest network that gives a good fit result?\n","2.  What do you observe when training networks with the same settings multiple times? Explain your observations.\n","3.  Try additional input features: Which one is most helpful?\n"]}]}